{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyML - Multilayer Perceptron (MLP)\n",
    "\n",
    "\n",
    "#### Federal University of Rio Grande do Norte\n",
    "\n",
    "#### Name: Thommas Kevin Sales Flores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install the libraries listed in the requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(f\"scikit-learn=={sklearn.__version__}\\n\")\n",
    "    f.write(f\"tensorflow=={tf.__version__}\\n\")\n",
    "    f.write(f\"pandas=={pd.__version__}\\n\")\n",
    "    f.write(f\"numpy=={np.__version__}\\n\")\n",
    "    f.write(f\"matplotlib=={matplotlib.__version__}\\n\")\n",
    "    f.write(f\"seaborn=={sns.__version__}\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Vehicle Attributes and Emissions Dataset\" contains comprehensive information on various vehicles manufactured in the year 2000. It includes details such as make, model, vehicle class, engine size, cylinder count, transmission type, and fuel type. Additionally, the dataset provides ranges for fuel consumption and CO2 emissions, offering insights into the environmental impact of each vehicle. The dataset encompasses a wide range of vehicle types, from compact to mid-size, and includes both conventional and high-performance models. With this information, analysts and researchers can study trends in vehicle characteristics, fuel efficiency, and emissions . This dataset serves as a valuable resource for understanding the automotive landscape and informing discussions on environmental sustainability and transportation policies.\n",
    "\n",
    "link: https://www.kaggle.com/datasets/krupadharamshi/fuelconsumption/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/FuelConsumption.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Removing rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removing duplicates if any\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe after cleaning\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['ENGINE SIZE','CYLINDERS','FUEL CONSUMPTION','COEMISSIONS ']])\n",
    "plt.savefig('.\\\\figures\\\\pairplot.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[['ENGINE SIZE','CYLINDERS','FUEL CONSUMPTION','COEMISSIONS ']].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the size of the figure\n",
    "plt.figure(figsize=(18,10))\n",
    "# Your existing code for generating the heatmap\n",
    "heatmap = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='coolwarm')\n",
    "# Adding values to the heatmap\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(len(corr.columns)):\n",
    "        plt.text(j + 0.5, i + 0.5, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', color='black', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=20, rotation=45)\n",
    "plt.yticks(fontsize=20, rotation=0)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "plt.savefig('.\\\\figures\\\\heatmap.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['ENGINE SIZE','CYLINDERS', 'COEMISSIONS ']]\n",
    "y=df[['FUEL CONSUMPTION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización min-max\n",
    "scaler = MinMaxScaler()\n",
    "normalized_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='mse', metrics=[ 'mse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                      batch_size=64,\n",
    "                      epochs=100,\n",
    "                      validation_split=0.1,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.\\models\\model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'r.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('.\\\\figures\\\\history_traing.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(error,name):\n",
    "\n",
    "    error_mean = np.mean(error)\n",
    "    error_std = np.std(error)\n",
    "    error_max = np.max(error)\n",
    "    error_min = np.min(error)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.distplot(error, hist=True, kde=True, bins=20, color='blue', hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 2})\n",
    "    plt.xlabel('Error', fontsize=13)\n",
    "    plt.ylabel('Density', fontsize=13)\n",
    "    plt.title('Error Distribution with Density Curve', fontsize=15)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "    plt.axvline(x=error_mean, color='red', linestyle='--', label='Mean')\n",
    "    plt.axvline(x=error_mean - error_std, color='green', linestyle='--', label='Mean - Std')\n",
    "    plt.axvline(x=error_max, color='purple', linestyle='--', label='Max')\n",
    "    plt.axvline(x=error_min, color='orange', linestyle='--', label='Min')\n",
    "\n",
    "    plt.text(error_mean, plt.ylim()[1]*0.9, f'Mean: {error_mean:.2f}', color='red', fontsize=12, ha='center')\n",
    "    plt.text(error_mean - error_std, plt.ylim()[1]*0.85, f'Std: {error_std:.2f}', color='green', fontsize=12, ha='center')\n",
    "    plt.text(error_max, plt.ylim()[1]*0.8, f'Max: {error_max:.2f}', color='purple', fontsize=12, ha='center')\n",
    "    plt.text(error_min, plt.ylim()[1]*0.75, f'Min: {error_min:.2f}', color='orange', fontsize=12, ha='center')\n",
    "    plt.savefig(f'.\\\\figures\\\\hist_{name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_training = y_train_pred - y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R²):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(error_training, 'training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_train.values, label = 'Real')\n",
    "plt.plot(y_train_pred, label = 'Prediction Train')\n",
    "plt.ylabel('FUEL CONSUMPTION', fontsize=13)\n",
    "plt.xlabel('Samples', fontsize=13)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(f'.\\\\figures\\\\prediction_train.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test = y_test_pred - y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R²):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(error_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test.values, label = 'Real')\n",
    "plt.plot(y_test_pred, label = 'Prediction Test')\n",
    "plt.ylabel('FUEL CONSUMPTION', fontsize=13)\n",
    "plt.xlabel('Samples', fontsize=13)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(f'.\\\\figures\\\\prediction_test.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Obtaining the model to be implemented in the microcontroller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Convert some hex value into an array for C programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "  c_str = ''\n",
    "\n",
    "  # Create header guard\n",
    "  c_str += '#ifdef __has_attribute\\n'\n",
    "  c_str += '#define HAVE_ATTRIBUTE(x) __has_attribute(x)\\n'\n",
    "  c_str += '#else\\n'\n",
    "  c_str += '#define HAVE_ATTRIBUTE(x) 0\\n'\n",
    "  c_str += '#endif\\n'\n",
    "  c_str += '#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))\\n'\n",
    "  c_str += '#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\\n'\n",
    "  c_str += '#else\\n'\n",
    "  c_str += '#define DATA_ALIGN_ATTRIBUTE\\n'\n",
    "  c_str += '#endif\\n\\n'\n",
    "\n",
    "  # Declare C variable\n",
    "  c_str += 'const unsigned char ' + var_name + '[]  DATA_ALIGN_ATTRIBUTE = {'\n",
    "  hex_array = []\n",
    "  for i, val in enumerate(hex_data) :\n",
    "\n",
    "    # Construct string from hex\n",
    "    hex_str = format(val, '#04x')\n",
    "\n",
    "    # Add formatting so each line stays within 80 characters\n",
    "    if (i + 1) < len(hex_data):\n",
    "      hex_str += ','\n",
    "    if (i + 1) % 12 == 0:\n",
    "      hex_str += '\\n '\n",
    "    hex_array.append(hex_str)\n",
    "\n",
    "  # Add closing brace\n",
    "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "  # Close out header guard\n",
    "  c_str += 'const int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "  return c_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Convert o model to Float32 and Int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for i in range(len(X_train)):\n",
    "        input_data = np.array([X_train[i]], dtype=np.float32)\n",
    "        yield [input_data]\n",
    "\n",
    "\n",
    "\n",
    "def converter_quantization_model(model, model_name):\n",
    "\n",
    "    # Convert o model to float32\n",
    "    converter_float32 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter_float32.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter_float32.target_spec.supported_types = [tf.float32]\n",
    "    converter_float32._experimental_lower_tensor_list_ops = False\n",
    "    converter_float32.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter_float32.representative_dataset = representative_dataset\n",
    "    tflite_model_float32 = converter_float32.convert()\n",
    "    print(tflite_model_float32)\n",
    "    with open(model_name+'_quant_float32' + '.h', 'w') as file:\n",
    "        file.write(hex_to_c_array(tflite_model_float32, model_name+'_quant_float32'))\n",
    "    with open(model_name+'_quant_float32.tflite', 'wb') as f:\n",
    "        f.write(tflite_model_float32)\n",
    "    size_model_tflite_float32 = os.path.getsize(model_name+'_quant_float32.tflite')\n",
    "    print(model_name+f'_quant_float32.tflite: {size_model_tflite_float32} Bytes')\n",
    "\n",
    "\n",
    "    # Convert o model to Int8\n",
    "    converter_int8 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter_int8.target_spec.supported_types = [tf.int8]\n",
    "    #converter_int8._experimental_lower_tensor_list_ops = False\n",
    "    converter_int8.representative_dataset = representative_dataset\n",
    "    converter_int8.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "    ]\n",
    "    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter_int8.experimental_new_converter = True\n",
    "    converter_int8.experimental_new_quantizer = True\n",
    "    converter_int8.experimental_new_calibrator = True\n",
    "    tflite_model_int8 = converter_int8.convert()\n",
    "    with open(model_name+'_quant_int8' + '.h', 'w') as file:\n",
    "        file.write(hex_to_c_array(tflite_model_int8, model_name+'_quant_int8'))\n",
    "    with open(model_name+'_quant_int8.tflite', 'wb') as f:\n",
    "        f.write(tflite_model_int8)\n",
    "    size_model_tflite_int8 = os.path.getsize(model_name+'_quant_int8.tflite')\n",
    "    print(model_name+f'_quant_int8.tflite: {size_model_tflite_int8} Bytes')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='.\\models\\model'\n",
    "converter_quantization_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Quantized Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quantization(model_path, X_test, y_test, quantization_type):\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Avaliar o modelo quantizado\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "    predictions = []\n",
    "    processing_times = []\n",
    "\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    \n",
    "    for X in X_test:\n",
    "        interpreter.set_tensor(input_index, [X])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        interpreter.invoke()\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        processing_times.append(processing_time)\n",
    "        output = interpreter.get_tensor(output_index)\n",
    "        predictions.append(output[0])\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "   \n",
    "    # Calcular a média e o desvio padrão das diferenças\n",
    "    result = { \"MSE\":mse,\n",
    "                \"MAE\": mae,\n",
    "                \"R2-Score\": r2,\n",
    "                \"Process time\": np.mean(processing_times)\n",
    "            }\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '.\\models\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_quant_float32 = evaluate_quantization(model_name + '_quant_float32.tflite', X_test, y_test, 'float32')\n",
    "eval_quant_float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_quant_int8 = evaluate_quantization(model_name + '_quant_int8.tflite', X_test, y_test, 'int8')\n",
    "eval_quant_int8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
